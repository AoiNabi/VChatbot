import gradio as gr
from llm_handler import LLMHandler
from voice_input import VoiceInput
import os

# Solo modelo DeepSeek a travÃ©s de Ollama
deepseek = LLMHandler("deepseek")
speech = VoiceInput()

def process(audio_path):
    if audio_path is None:
        return "âŒ No se recibiÃ³ audio.", None

    print(f"ğŸ“ Archivo de audio recibido (ruta): {audio_path}")

    if not os.path.exists(audio_path) or os.path.getsize(audio_path) == 0:
        return "âŒ El archivo no existe o estÃ¡ vacÃ­o.", None

    text = speech.transcribe(audio_path)
    if not text or text.startswith("[ERROR"):
        return f"ğŸ—£ï¸ TranscripciÃ³n: {text}\n\nâŒ No se pudo obtener texto para responder.", None

    response = deepseek.chat(text)

    return (
        f"ğŸ—£ï¸ TranscripciÃ³n: {text}\n\nğŸ¤– DeepSeek responde:\n{response}",
        audio_path
    )

ui = gr.Interface(
    fn=process,
    inputs=[
        gr.Audio(type="filepath", label="ğŸ™ï¸ Graba tu voz o sube un archivo")
    ],
    outputs=[
        "text",
        gr.Audio(label="ğŸ”Š Reproducir audio grabado")
    ],
    title="ğŸ¤– Chatbot con Voz + DeepSeek",
    description="Graba tu voz o sube un .wav; el modelo DeepSeek responderÃ¡ con texto generado."
)

ui.launch()
